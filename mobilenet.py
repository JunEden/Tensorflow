# -*- coding: utf-8 -*-
"""MobileNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DarRsjgk7e4ogCObIsEP7qDyTU9_ixFc
"""

!apt-get install python3.6

!pip install keras==2.2.4
!pip install numpy==1.19.5
!pip install pandas==1.1.5
!pip install tensorflow==2.5.0
!wget https://bootstrap.pypa.io/get-pip.py
!sudo python3.6 get-pip.py

!cp -r /usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.6/

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.applications import imagenet_utils
import random
import matplotlib.pyplot as plt

class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = {'batch':[], 'epoch':[]}
        self.accuracy = {'batch':[], 'epoch':[]}
        self.val_loss = {'batch':[], 'epoch':[]}
        self.val_acc = {'batch':[], 'epoch':[]}

    def on_batch_end(self, batch, logs={}):
        self.losses['batch'].append(logs.get('loss'))
        self.accuracy['batch'].append(logs.get('acc'))
        self.val_loss['batch'].append(logs.get('val_loss'))
        self.val_acc['batch'].append(logs.get('val_acc'))

    def on_epoch_end(self, batch, logs={}):
        self.losses['epoch'].append(logs.get('loss'))
        self.accuracy['epoch'].append(logs.get('acc'))
        self.val_loss['epoch'].append(logs.get('val_loss'))
        self.val_acc['epoch'].append(logs.get('val_acc'))

    def loss_plot(self, loss_type):
        iters = range(len(self.losses[loss_type]))
        plt.figure()
        # acc
        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')
        # loss
        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')
        if loss_type == 'epoch':
            # val_acc
            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')
            # val_loss
            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')
        plt.grid(True)
        plt.xlabel(loss_type)
        plt.ylabel('acc-loss')
        plt.legend(loc="upper right")
        plt.show()

history = LossHistory()

import glob
import pandas as pd 
good = glob.glob("/content/drive/MyDrive/poo_p_Augment/p*")
bad = glob.glob("/content/drive/MyDrive/bad_poo_p_Augment/bad_poo_*")
df = pd.DataFrame({
    "path":good + bad,
    "ans":[0] * len(good) + [1] * len(bad)
})
df

from tensorflow.keras.applications.mobilenet import MobileNet,preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization
from tensorflow.keras.layers import Dropout
cnn = MobileNet(include_top=False, input_shape=(224, 224, 3))
for l in cnn.layers:
    l.trainable = False
layers = [
    BatchNormalization(),
    GlobalAveragePooling2D(),
    Dropout(0.2),
    Dense(2, activation="softmax")
]
model = Sequential(cnn.layers + layers)
model.summary()

def prepare_image(file):
    img_path = df
    img = image.load_img(img_path + file, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array_expanded_dims = np.expand_dims(img_array, axis=0)
    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)

from tensorflow.keras.losses import SparseCategoricalCrossentropy
model.compile(loss=SparseCategoricalCrossentropy(),
              optimizer="adam",
              metrics=["accuracy"])

import random
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

p = df["path"]
idx = random.randint(0, len(p)-1)
img = Image.open(p[idx]).resize((224, 224)).convert("RGB")
img_np = np.array(img)
img_np_pre = preprocess_input(img_np)
print(img_np_pre)
plt.imshow(img)

x = np.array(df["path"])
y = np.array(df["ans"])

def data_generator(x, y, batch_size=20):
    while True:
        idx = np.random.randint(0, len(x), size=batch_size)
        x_batch, y_batch = x[idx], y[idx]
        x_final = []
        for path in x_batch:
            img = Image.open(path).resize((224, 224)).convert("RGB")
            img_pre = preprocess_input(np.array(img))
            x_final.append(img_pre)
        x_final = np.array(x_final)
        y_batch = np.array(y_batch)
        yield (x_final, y_batch)
gen = data_generator(x, y)
x_gen, y_gen = gen.__next__()
print(x_gen.shape)
print(y_gen.shape)

from sklearn.model_selection import train_test_split
goodx = x[y == 0]
badx = x[y == 1]
good120 = np.random.choice(goodx, 11000, replace=False)
good900, good100 = train_test_split(good120, test_size=0.1)
bad100 = np.random.choice(badx, 9000, replace=False)
bad100, bad10 = train_test_split(bad100, test_size=0.1)
x_train = np.concatenate((good900, bad100))
y_train = np.array([0] * len(good900) + [1] * len(bad100))
x_test = np.concatenate((good100, bad10))
y_test = np.array([0] * len(good100) + [1] * len(bad10))
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

train_generator = data_generator(x_train, y_train)
test_generator = data_generator(x_test, y_test)

model.fit_generator(train_generator,  #steps_per_epoch=每次美45張*上面的batch_size數量
                    steps_per_epoch=50,
                    #跑幾次訓練
                    epochs=5,
                    validation_data=test_generator,
                    validation_steps=5,
                    callbacks=[history])

testx, testy = test_generator.__next__()
model.predict(testx)

ori_imgs = []
for p in x_test:
    img = Image.open(p).resize((224, 224)).convert("RGB")
    ori_imgs.append(np.array(img))
ori_imgs = np.array(ori_imgs)
preprocess_imgs = preprocess_input(ori_imgs)
pre = model.predict(preprocess_imgs).argmax(axis=1)

trans = ["Good", "Bad"]
idx = np.nonzero(pre != y_test)[0]
pre_false_img = ori_imgs[idx]
pre_false_val = pre[idx]
pre_false_ori = y_test[idx]

plt.figure(figsize=(150, 150))
width = 20
height = len(idx) // width + 1
for i in range(len(idx)):
    plt.subplot(height, width, i+1)
    t = "[O]:{}\n[P]:{}".format(trans[pre_false_ori[i]],
                                trans[pre_false_val[i]])
    plt.title(t)
    plt.axis("off")
    plt.imshow(pre_false_img[i])

import requests
url = input("Enter:")
response = requests.get(url, stream=True, verify=False)
img = Image.open(response.raw).resize((224, 224)).convert("RGB")
img_np = preprocess_input(np.array(img).reshape(1, 224, 224, 3))
proba = model.predict(img_np)
ans = proba.argmax(axis=1)
print("預測:", trans[ans[0]])
print("機率:", proba[0])
plt.imshow(img)

history.loss_plot('epoch')

model.save("MobilE_Poop.h5")